{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImagesToArray(path:str):\n",
    "    '''\n",
    "    Loads all .jpg and .png files from the specified directory.\\n\n",
    "    Each image will be converted into an array of size (height x width x channels).\\n\n",
    "    The return numpy array is of dimensions (numberOfImages x height x width x channels).\\n\n",
    "    '''\n",
    "    imagesArray = []\n",
    "\n",
    "    counter = 0\n",
    "    for file in os.scandir(path):\n",
    "        filepath = os.fsdecode(file)\n",
    "        if(filepath.endswith(\".jpg\") or filepath.endswith(\".png\")):\n",
    "                imgArray = np.array(Image.open(filepath))\n",
    "                imagesArray.append(imgArray)\n",
    "                counter += 1                  \n",
    "    return np.array(imagesArray)\n",
    "\n",
    "def loadTrainingDataAndLabels(path:str, subdirectories):\n",
    "    '''\n",
    "    Loads the training data as numpy arrays and creates the corresponding labels.\\n\n",
    "    For this to work, the images should be under the folder <path> in separate subdirectories, one for each class.\\n\n",
    "    The labels will be inferred from the names of the subdirectories. \\n\n",
    "\n",
    "    Returns the training data as a numpy array with the dimensions (number_of_images x height x width x channels).\\n\n",
    "    Returns the labels as a numpy array with the dimensions (number_of_images).\n",
    "    '''\n",
    "\n",
    "    training_data = []\n",
    "    labels = []\n",
    "\n",
    "    for directory in subdirectories:\n",
    "        images_array = loadImagesToArray(os.path.join(path, directory))\n",
    "        training_data.extend(images_array)\n",
    "\n",
    "        labels.extend(np.full(len(images_array), directory))\n",
    "\n",
    "    training_data_array = np.array(training_data)\n",
    "    print(\"Shape of training_data: \", training_data_array.shape)\n",
    "    labels_array = np.array(labels)\n",
    "    print(\"Shape of labels: \", labels_array.shape)\n",
    "    \n",
    "    return training_data_array, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training_data:  (3316, 256, 256, 3)\n",
      "Shape of labels:  (3316,)\n"
     ]
    }
   ],
   "source": [
    "training_data, labels = loadTrainingDataAndLabels(\"./training_patches/\", [\"background\", \"ponds\", \"pools\", \"solar\", \"trampoline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geo_py/lib/python3.8/site-packages/scipy/__init__.py:135: UserWarning: NumPy 1.16.5 or above is required for this version of SciPy (detected version 1.16.2)\n",
      "  warnings.warn(\"NumPy 1.16.5 or above is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_categorical = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_data, labels_categorical, test_size=0.33, random_state=1, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, dtype=\"int8\")\n",
    "np.unique(y_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 10)      280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 10)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                3276820   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 3,277,625\n",
      "Trainable params: 3,277,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow import keras\n",
    "model = keras.models.Sequential()\n",
    "model.add(InputLayer(input_shape=(256,256,3)))\n",
    "model.add(Conv2D(filters=10, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 20s 604ms/step - loss: 496.5461 - accuracy: 0.9099 - val_loss: 181.5833 - val_accuracy: 0.9238\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 65s 2s/step - loss: 34.9841 - accuracy: 0.5796 - val_loss: 1.5911 - val_accuracy: 0.0269\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 26s 789ms/step - loss: 1.5313 - accuracy: 0.7938 - val_loss: 1.4744 - val_accuracy: 0.9238\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 23s 711ms/step - loss: 1.4197 - accuracy: 0.9394 - val_loss: 1.3733 - val_accuracy: 0.9238\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 31s 977ms/step - loss: 1.3200 - accuracy: 0.9394 - val_loss: 1.2806 - val_accuracy: 0.9238\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 57s 2s/step - loss: 1.2270 - accuracy: 0.9394 - val_loss: 1.1938 - val_accuracy: 0.9238\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.1398 - accuracy: 0.9394 - val_loss: 1.1119 - val_accuracy: 0.9238\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 29s 907ms/step - loss: 1.0575 - accuracy: 0.9394 - val_loss: 1.0358 - val_accuracy: 0.9238\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.9803 - accuracy: 0.9394 - val_loss: 0.9642 - val_accuracy: 0.9238\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.9083 - accuracy: 0.9394 - val_loss: 0.8982 - val_accuracy: 0.9238\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 30s 932ms/step - loss: 0.8417 - accuracy: 0.9394 - val_loss: 0.8381 - val_accuracy: 0.9238\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.7811 - accuracy: 0.9394 - val_loss: 0.7842 - val_accuracy: 0.9238\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 38s 1s/step - loss: 0.7261 - accuracy: 0.9394 - val_loss: 0.7352 - val_accuracy: 0.9238\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.6764 - accuracy: 0.9394 - val_loss: 0.6915 - val_accuracy: 0.9238\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 28s 891ms/step - loss: 0.6318 - accuracy: 0.9394 - val_loss: 0.6528 - val_accuracy: 0.9238\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 43s 1s/step - loss: 0.5920 - accuracy: 0.9394 - val_loss: 0.6184 - val_accuracy: 0.9238\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.5568 - accuracy: 0.9394 - val_loss: 0.5882 - val_accuracy: 0.9238\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 30s 928ms/step - loss: 0.5256 - accuracy: 0.9394 - val_loss: 0.5625 - val_accuracy: 0.9238\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4981 - accuracy: 0.9394 - val_loss: 0.5396 - val_accuracy: 0.9238\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4738 - accuracy: 0.9394 - val_loss: 0.5195 - val_accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras import Model\n",
    "import time\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePredictionToCsv(predictionDataframe: pd.DataFrame, filepath:str):\n",
    "    '''\n",
    "    Saves a dataframe containing the prediction for a single image to a CSV file.\n",
    "\n",
    "    @predictionDataFrame - The dataframe that contains the predictions and should be saved.\\n\n",
    "    @path - The path under which the CSV file should be saved.\n",
    "    @filename - The name under which the CSV file should be saved.\n",
    "    '''\n",
    "    #filepath =  os.path.splitext(filepath)[2]+\"_prediction.csv\"\n",
    "    filepath = \"./03_validation_results/\" +str(filepath.split('/')[2]) +\"_prediction.csv\"\n",
    "    predictionDataframe.to_csv(filepath, sep=\",\", index=False)\n",
    "\n",
    "def makePredictions(path:str, convnet:keras.Model, stepSize:int, windowSize):\n",
    "    '''\n",
    "    Traverses a folder that contains images for which predictions should be made.\\n\n",
    "    Creates a separate prediction CSV file for each image.\n",
    "\n",
    "    @path - The path containing the images for which predictions should be created.\n",
    "    '''\n",
    "\n",
    "    # For each image in path\n",
    "        # Perform sliding Window approach\n",
    "            # For each slide\n",
    "            # Store x_upper_left, y_upper_left, x_lower_right, y_lower_right\n",
    "            # Run image through convnet\n",
    "            # Run classifier on output\n",
    "            # If prediction != 'background'\n",
    "            # Store prediction in temp array\n",
    "        # Run non-max suppression to filter predictions\n",
    "        # Store predictions in csv\n",
    "    for file in os.scandir(path):\n",
    "        filepath = os.fsdecode(file)\n",
    "        \n",
    "        if((\"annotated\" in filepath) or not (filepath.endswith(\".jpg\") or filepath.endswith(\".png\"))):\n",
    "           continue\n",
    "        \n",
    "        createPredictionsForImage(filepath=filepath, convnet=convnet, stepSize=stepSize, windowSize=windowSize)\n",
    "\n",
    "\n",
    "def createPredictionsForImage(filepath:str, convnet:keras.Model, stepSize:int, windowSize):\n",
    "    '''\n",
    "    Creates the prediction CSV for one image.\n",
    "    '''\n",
    "\n",
    "    print(\"\\nCreating predictions for file: \", filepath)\n",
    "    create_predictions_start_time = time.time()\n",
    "    #image = Image.open(filepath)\n",
    "    imgArray = np.array(Image.open(filepath))\n",
    "    \n",
    "    patch_coordinates= []  \n",
    "    preprocessed_patches = []\n",
    "    counter = 0\n",
    "    patch_preprocessing_start_time = time.time()\n",
    "    \n",
    "    print(\"Starting sliding window to create patches of size: \", windowSize[0], \"x\", windowSize[1], \".\")\n",
    "    for(x,y,patch) in sliding_window(imageArray=imgArray, stepSize=stepSize, windowSize=windowSize):\n",
    "        if counter > 0 and counter%10000 == 0:\n",
    "            print(\"Still processing, reached patch\", counter)\n",
    "            print(\"Execution time for the last 10.000 patches: \", time.time()-patch_preprocessing_start_time, \" seconds.\")\n",
    "            patch_preprocessing_start_time = time.time()\n",
    "            print(\"Processing continues...\")\n",
    "        \n",
    "        # Skip if the size of a patch doesn't match the specified windowSize\n",
    "        if patch.shape[0] != windowSize[0] or patch.shape[1] != windowSize[1]:\n",
    "            continue\n",
    "    \n",
    "        # Save coordinates which are needed for a prediction\n",
    "        x_upper_left = x\n",
    "        y_upper_left = y\n",
    "        x_lower_right = x+windowSize[0]\n",
    "        y_lower_right = y+windowSize[1]\n",
    "        x_center = x+128\n",
    "        y_center = y+128\n",
    "\n",
    "        # Run the patch through the classification\n",
    "        preprocessed_patch = preprocess_input(patch)\n",
    "        preprocessed_patches.append(preprocessed_patch)\n",
    "        patch_coordinates.append([y_upper_left, x_upper_left, y_lower_right, x_lower_right])\n",
    "        counter +=1\n",
    "    \n",
    "    print(\"Finished preprocessing of the patches.\")\n",
    "    preprocessed_patches = np.array(preprocessed_patches)\n",
    "    patch_coordinates = np.array(patch_coordinates)\n",
    "    print(\"Shape of preprocessed patches: \", preprocessed_patches.shape)\n",
    "    print(\"Shape of patch coordinates: \", patch_coordinates.shape, \"\\n\")\n",
    "\n",
    "    # Get all predictions\n",
    "    print(\"Running patches through ConvNet and using classifier to predict labels...\")\n",
    "    prediction_start_time = time.time()\n",
    "    predicted_labels_encoded = pd.DataFrame(convnet.predict(preprocessed_patches), columns=[\"background\", \"ponds\", \"pools\", \"solar\", \"trampoline\"])\n",
    "    predicted_labels= predicted_labels_encoded.idxmax(1)\n",
    "    \n",
    "    # Create a column with the score for the predicted class\n",
    "    highest_scores = predicted_labels_encoded[[\"background\", \"ponds\", \"pools\", \"solar\", \"trampoline\"]].max(axis=1)\n",
    "    print(\"Shape of highest_scores: \", highest_scores.shape)\n",
    "\n",
    "    print(\"Finished predictions, execution time: \", time.time()-prediction_start_time, \" seconds.\\n\")\n",
    "    \n",
    "    print(\"Shape of patch_coordinates: \", patch_coordinates.shape)\n",
    "\n",
    "    # Combining patch coordinates and predictions\n",
    "    predictions_array=np.c_[highest_scores, predicted_labels, patch_coordinates]\n",
    "\n",
    "    print(\"Shape of combined predictions array (unfiltered): \", predictions_array.shape)\n",
    "\n",
    "    predictions_dataframe = pd.DataFrame(data=predictions_array, columns=[\"score\", \"label\", \"y_upper_left\", \"x_upper_left\", \"y_lower_right\", \"x_lower_right\"])\n",
    "    # Filter all predictions that contain the label \"background\"\n",
    "    predictions_dataframe = predictions_dataframe[predictions_dataframe.label != \"background\"]\n",
    "    print(\"Description of the predictions dataframe: \", predictions_dataframe.describe())\n",
    "\n",
    "    # Save prediction to csv\n",
    "    savePredictionToCsv(predictionDataframe=predictions_dataframe, filepath=filepath)\n",
    "    print(\"Saved predictions for file: \", filepath, \"\\n\")\n",
    "    print(\"Elapsed time: \", time.time()-create_predictions_start_time, \" seconds.\\n\")\n",
    "\n",
    "    \n",
    "def sliding_window(imageArray, stepSize:int, windowSize=(256,256)):\n",
    "    for y in range(0, imageArray.shape[0], stepSize):\n",
    "\t    for x in range(0, imageArray.shape[1], stepSize):\n",
    "\t\t\t# yield the current window\n",
    "\t\t    yield (x, y, imageArray[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating predictions for file:  ./02_validation_data_images/DQIMQN.png\n",
      "Starting sliding window to create patches of size:  256 x 256 .\n",
      "Still processing, reached patch 10000\n",
      "Execution time for the last 10.000 patches:  6.599049091339111  seconds.\n",
      "Processing continues...\n",
      "Finished preprocessing of the patches.\n",
      "Shape of preprocessed patches:  (14884, 256, 256, 3)\n",
      "Shape of patch coordinates:  (14884, 4) \n",
      "\n",
      "Running patches through ConvNet and using classifier to predict labels...\n",
      "Shape of highest_scores:  (14884,)\n",
      "Finished predictions, execution time:  101.9744520187378  seconds.\n",
      "\n",
      "Shape of patch_coordinates:  (14884, 4)\n",
      "Shape of combined predictions array (unfiltered):  (14884, 6)\n",
      "Description of the predictions dataframe:         score label y_upper_left x_upper_left y_lower_right x_lower_right\n",
      "count      0     0            0            0             0             0\n",
      "unique     0     0            0            0             0             0\n",
      "top      NaN   NaN          NaN          NaN           NaN           NaN\n",
      "freq     NaN   NaN          NaN          NaN           NaN           NaN\n",
      "Saved predictions for file:  ./02_validation_data_images/DQIMQN.png \n",
      "\n",
      "Elapsed time:  179.23685598373413  seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(\"./02_validation_data_images/\", convnet=model, stepSize=64, windowSize=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def nonMaxSuppressBoundingBoxes(path:str, iou_threshold:float, score_threshold:float):\n",
    "    '''\n",
    "    Loads prediction csv files from the path and performs the non-max-suppression for each of them.\\n\n",
    "    This method works per-class, i.e. the suppression is performed for each object class independently.\\n\n",
    "\n",
    "    @path - The path in which the to-be-processed csv files are located.\\n\n",
    "    @iou_threshold - The percentage of allowed overlap for predictions of the same class.\\n\\t\\t Must be a value between 0 and 1.\\n\n",
    "    @score_threshold - The minimum score a prediction must have to be considered values.\\n\\t\\t Predictions with a score < score_threshold will be removed from the predictions\\n.\n",
    "    '''\n",
    "\n",
    "    for file in os.scandir(path):\n",
    "        filepath = os.fsdecode(file)\n",
    "        \n",
    "\n",
    "        # Skip files that are not csv files or that contain \"suppressed\" in their name\n",
    "        if(not(filepath.endswith(\".csv\")) or (\"suppressed\" in filepath)):\n",
    "           continue\n",
    "\n",
    "        print(\"Creating suppressed csv for file: \", filepath, \"...\")\n",
    "        # New empty dataframe for the results\n",
    "        suppressed_predictions = pd.DataFrame(columns=[\"label\", \"y_upper_left\", \"x_upper_left\", \"y_lower_right\", \"x_lower_right\"])\n",
    "       \n",
    "        # Get the original predictions from a csv file\n",
    "        original_predictions = pd.read_csv(filepath, header=0)\n",
    "        \n",
    "        for pred_class in [\"background\", \"pool\", \"pond\", \"solar\", \"trampoline\"]:\n",
    "            \n",
    "            # Get labels, scores and coordinates for the class pred_class\n",
    "            class_original_predictions = original_predictions.loc[original_predictions[\"label\"]==pred_class]\n",
    "            labels = class_original_predictions[\"label\"]\n",
    "            scores = class_original_predictions[\"score\"]\n",
    "            coordinates = class_original_predictions.iloc[:, 2:6].astype(int)\n",
    "            \n",
    "            # Run the nonmax suppression and gather the boxes and labels of the remaining predictions\n",
    "            class_selected_boxes_indices = tf.image.non_max_suppression(boxes=coordinates, scores=scores, max_output_size=200, iou_threshold=iou_threshold, score_threshold=score_threshold )\n",
    "            class_selected_boxes = tf.gather(coordinates, class_selected_boxes_indices).numpy()\n",
    "            class_selected_labels = np.array([x.numpy().decode() for x in tf.gather(labels, class_selected_boxes_indices)])\n",
    "            class_predictions = pd.DataFrame(np.c_[class_selected_labels, class_selected_boxes], columns=[\"label\", \"y_upper_left\", \"x_upper_left\", \"y_lower_right\", \"x_lower_right\"])\n",
    "            \n",
    "            # Add the suppressed predictions of this class to the overall result\n",
    "            suppressed_predictions = suppressed_predictions.append(class_predictions)\n",
    "        \n",
    "        # Save the suppressed predictions to a csv file\n",
    "        new_filepath =  os.path.splitext(filepath)[0]+\"_suppressed.csv\"\n",
    "        suppressed_predictions.to_csv(new_filepath, sep=\",\", index=False)\n",
    "        print(\"Success! Saved suppressed predictions to: \", new_filepath)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('geo_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fb245b132a2be47283fe5f25201c6b65dd2f54345d845219426bdf4f2ce9823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
