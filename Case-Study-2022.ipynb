{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 2022 - Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For use in colab only\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/MyDrive/\n",
    "%cd ./da2-project2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "import augmentData\n",
    "import loadAndStoreData\n",
    "import processData\n",
    "import drawImages\n",
    "import loadAdditionalData\n",
    "reload(augmentData)\n",
    "reload(loadAndStoreData)\n",
    "reload(processData)\n",
    "reload(drawImages)\n",
    "reload(loadAdditionalData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the training data is augmented. The function allows to choose the classes for which the augmentations should be done.\n",
    "It also allows to define the augmentation techniques that are used. \n",
    "\n",
    "For each augmentation technique a new subfolder is created. Each subfolder contains the augmented images of the classes chosen.\n",
    "Depending on the augmentation techniques chosen, this process may neeed a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load additional data\n",
    "# Loads the additional training data from the specified directories\n",
    "# Each tupel specifies the path to the additional training images and the class that the images belong to\n",
    "# Result data are saved udnder\n",
    "loadAdditionalData.loadAdditionalData(path=\"additional_data\", directories_and_labels=[(\"solar_alt\", \"solar\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentData.performDataAugmentation(\n",
    "    directory=\"training_patches/\", \n",
    "    categories=[\"pond\", \"pool\",\"solar\",\"trampoline\"], \n",
    "    augmentations=[\"rotate_images\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentData.performDataAugmentation(\n",
    "    directory=\"additional_data/\", \n",
    "    categories=[\"pond\", \"pool\",\"solar\",\"trampoline\"], \n",
    "    augmentations=[\"rotate_images\", \"zoom_images\", \"change_brightness\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section loads the training patches into a numpy array and creates the corresponding label vector.\n",
    "The result are X_train, X_val, y_train and y_val. \n",
    "\n",
    "The images are converted to RGB values, which is why there are 3 channels in the training data.\n",
    "\n",
    "The training data sets are of dimension (number_of_instances x height x width x 3 channels). \n",
    "The label vectors only have one dimension (number_of_instances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, labels = loadAndStoreData.loadTrainingDataAndLabels(\n",
    "    folders=[\n",
    "        \"training_patches/\", \n",
    "        \"training_patches_rotation\",\n",
    "        \"additional_data\" \n",
    "    ], \n",
    "    subdirectories=[\"background\", \"pond\", \"pool\", \"solar\", \"trampoline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version (classiscal convnet)\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels_categorical = processData.labels_to_categorical(labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_data, labels_categorical, test_size=0.33, random_state=1, stratify=labels)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inception v3 version\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing only needed for inception net\n",
    "# training_data =  preprocess_input(training_data)\n",
    "\n",
    "labels_categorical = processData.labels_to_categorical(labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_data, labels_categorical, test_size=0.33, random_state=1, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = processData.encodeLabels(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old verision (classical convnet)\n",
    "'''\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(InputLayer(input_shape=(256,256,3)))\n",
    "model.add(Conv2D(filters=10, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception v3 for feature extraction\n",
    "from tensorflow import keras\n",
    "base_model = keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(256, 256, 3))\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on X_train\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train_encoded, \n",
    "                    epochs=25,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model.fit(training_data, \n",
    "                    labels_encoded, \n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.1,\n",
    "                   )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "preds = model.predict(X_val)\n",
    "preds_argmaxed = np.apply_along_axis(np.argmax, 1, preds)\n",
    "f1_score(y_val,preds_argmaxed, average='macro'), accuracy_score(y_val, preds_argmaxed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, preds_argmaxed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processData.makePredictions(\"validation_images\", convnet=model, stepSize=64, windowSize=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "preprocessed_patches = None\n",
    "del preprocessed_patches\n",
    "patch_coordinates = None\n",
    "del patch_coordinates\n",
    "X_train = None\n",
    "del X_train\n",
    "X_val = None \n",
    "del X_val\n",
    "y_train = None\n",
    "del y_train\n",
    "y_val = None\n",
    "training_data = None\n",
    "del training_data\n",
    "X_train_preprocessed = None\n",
    "del X_train_preprocessed\n",
    "predictions_array = None\n",
    "del predictions_array\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processData.nonMaxSuppressBoundingBoxes(\"validation_images/\", iou_threshold=0.0, score_threshold=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Images with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawImages.saveOrPrintImages(path=\"./validation_images\", print_to_output=False, valBoundingBoxes=True,saveImagesPath=\"./validation_images\", thickness=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def calc_performance(gt_path, pred_path, image_name=None, verbose=0):\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "\n",
    "    # Create default performance values\n",
    "    performances = {\n",
    "        'file': image_name,\n",
    "        'tp': 0,\n",
    "        'fn': 0,\n",
    "        'fp': 0,\n",
    "        'f1': 0,\n",
    "    }\n",
    "\n",
    "    # Load ground truth\n",
    "    with open(gt_path) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row = {k: int(row[k]) if k != 'label' else row[k]\n",
    "                   for k in row.keys()}\n",
    "            ground_truth.append(row)\n",
    "\n",
    "    # load predictions if path exists\n",
    "    if os.path.exists(pred_path):\n",
    "        with open(pred_path) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                row = {k: int(row[k]) if k != 'label' else row[k]\n",
    "                       for k in row.keys()}\n",
    "                predictions.append(row)\n",
    "\n",
    "    # Number of false positives equals number of left predictions\n",
    "    performances['fp'] = max(len(predictions) - len(ground_truth), 0)\n",
    "\n",
    "    for j, gt in enumerate(ground_truth):\n",
    "        gt_box = Polygon([(gt['y_upper_left'],  gt['x_upper_left']),\n",
    "                          (gt['y_upper_left'],  gt['x_lower_right']),\n",
    "                          (gt['y_lower_right'], gt['x_lower_right']),\n",
    "                          (gt['y_lower_right'], gt['x_upper_left'])])\n",
    "\n",
    "        if gt_box.area != (256. * 256.):\n",
    "            print(\n",
    "                f'### Warning {j}: false ground truth shape of {gt_box.area} detected in {image_name}!')\n",
    "            print(gt['y_lower_right'] - gt['y_upper_left'],\n",
    "                  gt['x_lower_right'] - gt['x_upper_left'])\n",
    "\n",
    "        best_found_iou = (None, 0.)  # (idx, IoU)\n",
    "        for i, pred in enumerate(predictions):\n",
    "            if gt['label'] == pred['label']:\n",
    "                pred_box = Polygon([(pred['y_upper_left'],  pred['x_upper_left']),\n",
    "                                    (pred['y_upper_left'],\n",
    "                                     pred['x_lower_right']),\n",
    "                                    (pred['y_lower_right'],\n",
    "                                     pred['x_lower_right']),\n",
    "                                    (pred['y_lower_right'], pred['x_upper_left'])])\n",
    "\n",
    "                if pred_box.area != (256. * 256.):\n",
    "                    print(\n",
    "                        f'### Warning {i}: false predicted shape of {pred_box.area} detected in {image_name}!')\n",
    "                    print(pred['y_lower_right'] - pred['y_upper_left'],\n",
    "                          pred['x_lower_right'] - pred['x_upper_left'])\n",
    "\n",
    "                # Calculate IoU\n",
    "                next_iou = (gt_box.intersection(pred_box).area +\n",
    "                            1) / (gt_box.union(pred_box).area + 1)\n",
    "\n",
    "                # If the next found IoU is larger than the previous found IoU -> override\n",
    "                if next_iou > best_found_iou[1]:\n",
    "                    best_found_iou = (i, next_iou)\n",
    "\n",
    "        # Append metric. If IoU is larger 0.5, then its a true positive, else false negative\n",
    "        if best_found_iou[0] is not None and best_found_iou[1] >= 0.5:\n",
    "            del predictions[best_found_iou[0]]  # Remove prediction from list!\n",
    "            performances['tp'] += 1  # Increase number of True Positives\n",
    "            if verbose == 1:\n",
    "                print(\n",
    "                    f'Found correct prediction with IoU of {round(best_found_iou[1], 3)} and label {gt[\"label\"]}!')\n",
    "        else:\n",
    "            performances['fn'] += 1  # Increase number of False Negatives\n",
    "            if verbose == 1:\n",
    "                print(\n",
    "                    f'Found false prediction with IoU of {round(best_found_iou[1], 3)} and label {gt[\"label\"]}!')\n",
    "\n",
    "    # Calculate F1-Score\n",
    "    performances['f1'] = (performances['tp'] + 1e-8) / \\\n",
    "        (performances['tp'] + 0.5 *\n",
    "         (performances['fp'] + performances['fn']) + 1e-8)\n",
    "    return performances\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = 'validation_images'  # Change if needed\n",
    "\n",
    "    # Iterate over all validation images\n",
    "    for image_path in glob.glob(path + '/*.png'):\n",
    "        image_name = image_path.split('/')[-1]\n",
    "        gt_path = image_path[:-4] + '.csv'  # Ground Truth path\n",
    "        pred_path = image_path[:-4] + \\\n",
    "            '_prediction_suppressed.csv'  # Prediction path\n",
    "        performance = calc_performance(gt_path, pred_path, image_name)\n",
    "        print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a578b60687b99a82ca78389cf5818de06cdae5f0e0fb7a238655a79bce45af2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
