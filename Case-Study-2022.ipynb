{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 2022 - Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "import augmentData\n",
    "import loadAndStoreData\n",
    "import processData\n",
    "import drawImages\n",
    "reload(augmentData)\n",
    "reload(loadAndStoreData)\n",
    "reload(processData)\n",
    "reload(drawImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the training data is augmented. The function allows to choose the classes for which the augmentations should be done.\n",
    "It also allows to define the augmentation techniques that are used. \n",
    "\n",
    "For each augmentation technique a new subfolder is created. Each subfolder contains the augmented images of the classes chosen.\n",
    "Depending on the augmentation techniques chosen, this process may neeed a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentData.performDataAugmentation(\n",
    "    directory=\"training_patches/\", \n",
    "    categories=[\"ponds\", \"pools\",\"solar\",\"trampoline\"], \n",
    "    augmentations=[\"rotate_images\", \"move_images\", \"zoom_images\", \"change_brightness\", \"combine_augmentations\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section loads the training patches into a numpy array and creates the corresponding label vector.\n",
    "The result are X_train, X_val, y_train and y_val. \n",
    "\n",
    "The images are converted to RGB values, which is why there are 3 channels in the training data.\n",
    "\n",
    "The training data sets are of dimension (number_of_instances x height x width x 3 channels). \n",
    "The label vectors only have one dimension (number_of_instances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, labels = loadAndStoreData.loadTrainingDataAndLabels(\n",
    "    folders=[\n",
    "        \"training_patches/\",\n",
    "        \"training_patches_brightnessdown\",\n",
    "        \"training_patches_brightnessup\",\n",
    "        \"training_patches_combined\",\n",
    "        \"training_patches_down\",\n",
    "        \"training_patches_left\",\n",
    "        \"training_patches_right\",\n",
    "        \"training_patches_rotation\",\n",
    "        \"training_patches_up\",\n",
    "        \"training_patches_zoom\"\n",
    "    ], \n",
    "    subdirectories=[\"background\", \"ponds\", \"pools\", \"solar\", \"trampoline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels_categorical = processData.labels_to_categorical(labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_data, labels_categorical, test_size=0.33, random_state=1, stratify=labels)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = processData.encodeLabels(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(InputLayer(input_shape=(256,256,3)))\n",
    "model.add(Conv2D(filters=10, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train_encoded, \n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "preds = model.predict(X_val)\n",
    "preds_argmaxed = np.apply_along_axis(np.argmax, 1, preds)\n",
    "f1_score(y_val,preds_argmaxed, average='macro'), accuracy_score(y_val, preds_argmaxed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, preds_argmaxed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processData.makePredictions(\"validation_images\", convnet=model, stepSize=64, windowSize=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "preprocessed_patches = None\n",
    "del preprocessed_patches\n",
    "patch_coordinates = None\n",
    "del patch_coordinates\n",
    "X_train = None\n",
    "del X_train\n",
    "X_val = None \n",
    "del X_val\n",
    "y_train = None\n",
    "del y_train\n",
    "y_val = None\n",
    "training_data = None\n",
    "del training_data\n",
    "X_train_preprocessed = None\n",
    "del X_train_preprocessed\n",
    "predictions_array = None\n",
    "del predictions_array\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processData.nonMaxSuppressBoundingBoxes(\"validation_images/\", iou_threshold=0.0, score_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Images with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawImages.saveOrPrintImages(path=\"./validation_images\", print_to_output=False, valBoundingBoxes=True,saveImagesPath=\"./validation_images\", thickness=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a578b60687b99a82ca78389cf5818de06cdae5f0e0fb7a238655a79bce45af2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
